settings:
  mode: retraining # training, retraining, inference
  task: follow_lane_carla # follow_line_gazebo, follow_lane_gazebo, autoparking_gazebo
  algorithm: ppo_continuous # qlearn, dqn, ddpg, ppo
  simulator: carla # openai, carla, gazebo, sumo
  environment_set: carla_environments # gazebo_environments, carla_environments
  env: follow_lane # Town01, simple, nurburgring, montreal, curves, simple_laser, manual, autoparking
  agent: auto_carla # f1, autoparkingRL, auto_carla, mountain_car, robot_mesh, cartpole, turtlebot
  actions: slow # slow, fast
  states: sp5 #image, sp1 (simplified perception with 1 point), sp3 (simplified perception with 3 points), spn (simplified perception with n points)
  rewards: followline_center # followline_center, followline_center_v_w_linear
  framework: TensorFlow # TensorFlow, Pytorch
  total_episodes: 500000
  training_time: 72
  models_dir: "./checkpoints"
  recorder_carla_dir: "./recorders"
  logs_dir: "./logs"
  metrics_dir: "./metrics"
  debug_stats: false
  show_monitoring: false
  steps_to_decrease: 20000
  decrease_substraction: 0.005
  decrease_min: 0.01
  reward_params:
    function: pow
    punish_zig_zag_value: 0.5
    punish_ineffective_vel: 2 # velocity below which reward is not calculated (0)
    beta_1: 0.8


ros:
  ros_master_uri: "11311"
  gazebo_master_uri: "11345"

retraining:
  ppo:
    retrain_ppo_tf_model_name: IMPROVED/20240603-212457MaxReward-2454_Epoch-98_AM-434.1629130568324_AS-4.981970093125234
inference:
  ppo:
    inference_ppo_tf_actor_model_name:
    inference_ppo_tf_critic_model_name:

algorithm:
  ppo:
    gamma: 0.9
    epsilon: 0.1
    std_dev: 0.05
    episodes_update: 50 # episodes how often the algorithm is trained
    replay_memory_size: 50_000
    memory_fraction: 0.20
    critic_lr: 0.0003
    actor_lr: 0.0002
    model_name: PPO_Actor_conv2d32x64_Critic_conv2d32x64

agents:
  auto_carla:
    camera_params:
      width: 640
      height: 480
      center_image: 320
      raw_image: False
      image_resizing: 100
      new_image_size: 32
      num_regions: 16
      lower_limit: 220

states:
  image:
    0: [3]
  sp1:
    0: [40] #TODO
  sp3:
    0: [10, 50, 150]
  sp5:
    0: [ 320, 340, 370, 390, 420 ]
  sp10:
    0: [370, 380, 390, 400, 410, 430, 470, 500, 530, 560]
  spn:
    0: [10]

actions:
  slow:
    v: [0, 1]
    w: [-0.5, 0.5]

rewards:
  followline_center:
    from_10: 10
    from_02: 2
    from_01: 1
    penal: -100
    min_reward: 5_000
    highest_reward: 100
  followline_center_v_w_linear: # only for continuous actions
    penal: 0
    min_reward: 1_000
    highest_reward: 100

carla_environments:
  follow_lane:
    env_name: CarlaEnv-v0
    town: Town04 #Town01, Town02, Town03, Town04, Town05, Town10HD
    # Town01_Opt, Town02_Opt, Town03_Opt, Town04_Opt, Town05_Opt, Town10HD_Opt
    car: model1
    weather: ClearNoon #dynamic, argparse
    traffic_pedestrians: False
    city_lights: False
    car_lights: False
    estimated_steps: 100000
    save_episodes: 5 # not used in this carla ppo
    save_every_step: 100 # not used in this carla ppo
    init_pose:
    goal_pose:
    filter: vehicle.*
    generation: "2"
    rolename: "hero" #name
    gamma: 2.2 #for camera
    sync: True #syncronous mode or async
    detection_mode: lane_detector
    fixed_delta_seconds: 0.1
    async_forced_delta_seconds: 0
    reset_threshold: 0.3
    alternate_pose: True
    waypoints_meters: 5 #distance between waypoints in meters
    waypoints_init: 6912 # {6912} 6927 1471
    waypoints_target: 959 #961
    waypoints_lane_id: -3
    waypoints_road_id: 1401

carla:
  carla_server: localhost
  carla_client: 2000
  manager_port: 8007
